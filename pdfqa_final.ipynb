{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ankitrajmehta/pdf-Question-answer/blob/main/pdfqa_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain\n",
        "!pip install sentence-transformers\n",
        "!pip install chromadb\n",
        "!pip install pypdf"
      ],
      "metadata": {
        "id": "YVv9vW8_lRec"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zcW4GunbjXRO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain import HuggingFaceHub\n",
        "from langchain.chains import ConversationalRetrievalChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8rh9oHxdjmBB"
      },
      "outputs": [],
      "source": [
        "def pdf_to_vec(pdf):\n",
        "  reader = PyPDFLoader(pdf)\n",
        "  pages = reader.load()\n",
        "  chunker = RecursiveCharacterTextSplitter(chunk_size=800,chunk_overlap=100)\n",
        "  chunks = chunker.split_documents(pages)\n",
        "  embeddings = HuggingFaceEmbeddings()\n",
        "  vector_store = Chroma.from_documents(chunks, embedding=embeddings)\n",
        "  return vector_store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Dyp5YeR0jnsi"
      },
      "outputs": [],
      "source": [
        "db = pdf_to_vec('LOCATION OF PDF')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U2QR77T7VA9_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "O6UgupoCkaUo"
      },
      "outputs": [],
      "source": [
        "os.environ['HUGGINGFACEHUB_API_TOKEN'] = 'HUGGINGFACE API KEY' #enter huggingface api key. You can get it by creating an account on huggingface.co"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RhFBj5ODkpQF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b519d6e-5277-4cb9-ac83-84ea9e56c4ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:127: FutureWarning: '__init__' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
            "  warnings.warn(warning_message, FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "llm = HuggingFaceHub(repo_id=\"google/flan-t5-xxl\", model_kwargs={\"temperature\":0.5})#google/flan-t5-xxl\n",
        "chat_history=[]\n",
        "model = ConversationalRetrievalChain.from_llm(llm = llm, retriever= db.as_retriever())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mW_xNUu1knP-"
      },
      "outputs": [],
      "source": [
        "query = input(\"Enter question: \")\n",
        "result = model({\"question\": query, \"chat_history\": chat_history})\n",
        "result[\"answer\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eRiTKoKdk_FM"
      },
      "outputs": [],
      "source": [
        "chat_history = [(query, result[\"answer\"])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "segtfXFHk_y_"
      },
      "outputs": [],
      "source": [
        "chat_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-2BETX26liTF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce3699bb-8573-4a7c-c162-a2004dd2da4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter question: Who won the war?\n",
            "the victorious Allies\n",
            "To ask more question enter 'y' else print any other keyy\n",
            "Enter question: Who were they?\n",
            "the victorious Allies\n",
            "To ask more question enter 'y' else print any other keyy\n",
            "Enter question: who were the allies?\n",
            "United States, the United Kingdom, and France) and the Soviet Union\n",
            "To ask more question enter 'y' else print any other keyn\n"
          ]
        }
      ],
      "source": [
        "repeat = True\n",
        "while repeat:\n",
        "  query = input(\"Enter question: \")\n",
        "  result = model({\"question\": query, \"chat_history\": chat_history})\n",
        "  print(result[\"answer\"])\n",
        "  chat_history = [(query, result[\"answer\"])]\n",
        "  r = input(\"To ask more question enter 'y' else print any other key: \")\n",
        "  if r.lower() != 'y':\n",
        "    repeat = False"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jAjA4HVUGgjr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP5o+NR0RpB0G7mgURCT/kH",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}